# Author: Ethan Lee
# 2024/3/16 16:27

import pyrealsense2 as rs
import numpy as np
import cv2
import os
import rc_utils

# Configure depth and color streams
# noinspection PyArgumentList
pipeline = rs.pipeline()
config = rs.config()

config.enable_stream(rs.stream.depth, 640, 360, rs.format.z16, 30)
config.enable_stream(rs.stream.color, 640, 360, rs.format.bgr8, 30)
# Align the depth frame to color frame
align = rs.align(rs.stream.color)
# Start streaming
pipeline.start(config)


# 定义视频参数
# output_path = 'C:/Users/123/Desktop/test/img'
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
frame_width = 640
frame_height = 360
# out = cv2.VideoWriter(output_path, fourcc, 20.0, (frame_width, frame_height))
count = 3001

"""
def click_to_get_coordinates(event, x, y, flags, param):
    if event == cv2.EVENT_LBUTTONDOWN:
        print("点击坐标：", x, y)
        print("深度值：", aligned_depth_frame.get_distance(x, y))
        print("----------------------")
"""

if __name__ == '__main__':
    while True:
        img_name = os.path.join('C:/Users/123/Desktop/new_test', f'img_{count}.jpg')  # 储存路径和命名规则
        frames = pipeline.wait_for_frames()
        aligned_frames = align.process(frames)

        # Get aligned frames
        aligned_depth_frame = aligned_frames.get_depth_frame()
        color_frame = aligned_frames.get_color_frame()

        # Validate that both frames are valid
        if not aligned_depth_frame or not color_frame:
            continue

        # Convert images to numpy arrays
        depth_image = np.asanyarray(aligned_depth_frame.get_data())
        color_image = np.asanyarray(color_frame.get_data())

        # 滤除不满足深度要求的点（以黑色填充）
        # 设置深度阈值 (单位为米)
        depth_min = 0
        depth_max = 100

        # 将深度图像转换为有效范围内的掩码
        mask = np.logical_and(depth_image > depth_min * 1000, depth_image < depth_max * 1000)
        # 创建一个结构元素,用于开运算
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))

        # 对mask进行开运算
        mask = cv2.morphologyEx(mask.astype(np.uint8), cv2.MORPH_OPEN, kernel)

        # 将不满足深度要求的点在彩色图像上变为黑色
        color_image[np.logical_not(mask)] = [0, 0, 0]
        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)
        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)

        # Stack both images horizontally
        images = color_image
        # Show images
        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)
        cv2.imshow('RealSense', images)
        images = cv2.flip(images, 1)
        # out.write(images)
        # cv2.imwrite(img_name, images)

        count += 1
        print(count)
        if cv2.waitKey(1) == 27:
            break

        # Click to print depth
        # noinspection PyTypeChecker
        # cv2.setMouseCallback('RealSense', click_to_get_coordinates)
    pipeline.stop()
    cv2.destroyAllWindows()
# print("Video saved to:", os.path.abspath(output_path))
